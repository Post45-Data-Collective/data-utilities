{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author VIAF Download Via LCCN\n",
    "\n",
    "This script will talk to viaf.org to find the VIAF for an LCCN. \n",
    "\n",
    "It is a requirement that you have a field with the LCCN in it\n",
    "\n",
    "This script modifies the TSV file itself in batches, should the script timeout or other error you can rerun it and it will pickup where it left off, always run it on a backup of your orginal data files.\n",
    "\n",
    "It creates a new column in the file `author_viaf` with the VIAF ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import string\n",
    "import unicodedata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "Set these variables below based on your setup\n",
    "\n",
    "`path_to_tsv` - the path to the TSV file you want to run it on\n",
    "\n",
    "`id_column_name` - the name of the column header that contains LCCN value\n",
    "\n",
    "`user_agent` - this is the value put into the headers on each request, it is good practice to identifiy your client/project when working with open free APIs\n",
    "\n",
    "`pause_between_req` - number of seconds to wait between each API call\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tsv = \"/Users/m/Downloads/data-tmp/hathitrust_post45fiction_metadata.tsv\"\n",
    "id_column_name = \"author_lccn\"\n",
    "user_agent = 'YOUR PROJECT NAME HERE'\n",
    "pause_between_req = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_viaf(d):\n",
    "\n",
    "    if type(d[id_column_name]) != str:     \n",
    "        # no heading to use skipp\n",
    "        return d\n",
    "        \n",
    "    # if there is already a value skip it\n",
    "    if 'author_viaf' in d:        \n",
    "        if pd.isnull(d['author_viaf']) == False:        \n",
    "            print('Skip',d[id_column_name],d['author_viaf'])\n",
    "            return d\n",
    "\n",
    "\n",
    "    headers={'User-Agent': user_agent}\n",
    "    url = f\"https://viaf.org/viaf/sourceID/LC%7C{d[id_column_name]}\"\n",
    "\n",
    "    r = requests.get(url,headers=headers,allow_redirects=False)\n",
    "    if r.status_code == 404:\n",
    "        return d\n",
    "\n",
    "    viaf = r.headers['Location'].split('/')[-1]\n",
    "    d['author_viaf'] = viaf\n",
    "\n",
    "    time.sleep(pause_between_req)\n",
    "\n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tsv\n",
    "df = pd.read_csv(path_to_tsv, sep='\\t', header=0, low_memory=False)\n",
    "\n",
    "# we are going to split the dataframe into chunks so we can save our progress as we go but don't want to save the entire file on on every record operation\n",
    "n = 500  #chunk row size\n",
    "list_df = [df[i:i+n] for i in range(0,df.shape[0],n)]\n",
    "\n",
    "# loop through each chunk\n",
    "for idx, df_chunk in enumerate(list_df):\n",
    "\n",
    "    print(\"Working on chunk \", idx, 'of', len(list_df))\n",
    "\n",
    "    # if you want it to skip X number of chunks uncomment this\n",
    "    # if idx < 88:\n",
    "    #     continue\n",
    "\n",
    "    list_df[idx] = list_df[idx].apply(lambda d: add_viaf(d),axis=1 )  \n",
    "\n",
    "    reformed_df = pd.concat(list_df)\n",
    "    reformed_df.to_csv(path_to_tsv, sep='\\t')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This last block just does QA on the data to see what if any rows were not populated\n",
    "\n",
    "# df = pd.read_csv(path_to_tsv, sep='\\t', header=0, low_memory=False)\n",
    "# print(\"There are \", df['hathi_marc'].isnull().any().sum(), 'rows with no hathi_marc column populated, here are their', id_column_name, 'values:')\n",
    "# res = df.loc[df['hathi_marc'].isnull(), id_column_name].tolist()\n",
    "# print(print(res))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
