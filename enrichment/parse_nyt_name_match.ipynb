{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zzzzz\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "Set these variables below based on your setup\n",
    "\n",
    "`path_to_tsv` - the path to the TSV file you want to run it on\n",
    "\n",
    "\n",
    "\n",
    "`oclc_classify` - column where oclc_classify xml blob is stored\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tsv = \"/Users/m/Downloads/data-tmp/nyt_hardcover_fiction_bestsellers-titles.tsv\"\n",
    "path_to_tsv2 = \"/Users/m/Downloads/data-tmp/nyt_hardcover_fiction_bestsellers-lists.tsv\"\n",
    "\n",
    "\n",
    "# load the hathi people data\n",
    "\n",
    "nyt_titles = pd.read_csv(path_to_tsv, sep='\\t', header=0, low_memory=False)\n",
    "cache = {}\n",
    "\n",
    "for i, row in nyt_titles.iterrows():\n",
    "\n",
    "    try:\n",
    "        if row['author'].strip()+row['title'].strip() not in cache:\n",
    "            cache[row['author'].strip()+row['title'].strip()] = dict(row)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(len(cache))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_name(d):\n",
    "\n",
    "\n",
    "    if type(d['author'] ) == str and type(d['title']) == str:\n",
    "        if d['author'].strip() + d['title'].strip() in cache:\n",
    "            \n",
    "            print(d['author'].strip() + d['title'].strip())\n",
    "\n",
    "            # print(cache[d['author'].strip() + d['title'].strip()]['author_authorized_heading'])\n",
    "            # if 'author_authorized_heading' in cache:\n",
    "            d['author_authorized_heading'] = cache[d['author'].strip() + d['title'].strip()]['author_authorized_heading']\n",
    "            \n",
    "            if 'author_lccn' in cache[d['author'].strip() + d['title'].strip()]:\n",
    "                d['author_lccn'] = cache[d['author'].strip() + d['title'].strip()]['author_lccn']\n",
    "\n",
    "            if 'author_viaf' in cache[d['author'].strip() + d['title'].strip()]:\n",
    "                d['author_viaf'] = cache[d['author'].strip() + d['title'].strip()]['author_viaf']\n",
    "\n",
    "            if 'author_wikidata' in cache[d['author'].strip() + d['title'].strip()]:\n",
    "                d['author_wikidata'] = cache[d['author'].strip() + d['title'].strip()]['author_wikidata']\n",
    "\n",
    "            if 'oclc_eholdings' in cache[d['author'].strip() + d['title'].strip()]:\n",
    "                d['oclc_eholdings'] = cache[d['author'].strip() + d['title'].strip()]['oclc_eholdings']\n",
    "\n",
    "            if 'oclc_holdings' in cache[d['author'].strip() + d['title'].strip()]:\n",
    "                d['oclc_holdings'] = cache[d['author'].strip() + d['title'].strip()]['oclc_holdings']\n",
    "\n",
    "            if 'oclc_owi' in cache[d['author'].strip() + d['title'].strip()]:\n",
    "                d['oclc_owi'] = cache[d['author'].strip() + d['title'].strip()]['oclc_owi']\n",
    "\n",
    "            if 'oclc_isbn' in cache[d['author'].strip() + d['title'].strip()]:\n",
    "                d['oclc_isbn'] = cache[d['author'].strip() + d['title'].strip()]['oclc_isbn']\n",
    "\n",
    "\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_tsv2, sep='\\t', header=0, low_memory=False)\n",
    "\n",
    "df.drop(df.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "\n",
    "# run our function over all of them\n",
    "df = df.apply(lambda d: match_name(d),axis=1 )  \n",
    "# # overwrite back out\n",
    "df.to_csv(path_to_tsv2, sep='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
