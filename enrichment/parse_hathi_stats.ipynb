{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hathi Stats\n",
    "\n",
    "Shows some stats for various metrics in a Hathi based file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "Set these variables below based on your setup\n",
    "\n",
    "`path_to_tsv` - the path to the TSV file you want to run it on\n",
    "\n",
    "`user_agent` - this is the value put into the headers on each request, it is good practice to identifiy your client/project when working with open free APIs\n",
    "\n",
    "`pause_between_req` - number of seconds to wait between each API call\n",
    "\n",
    "`author_viaf` - column where viaf number is stored\n",
    "\n",
    "`author_lccn` - column where lccn  number is stored\n",
    "\n",
    "`author_wikidata` - column where qid number is stored\n",
    "\n",
    "`author_authorized_heading` - the column where the authorized name is stored\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tsv = \"/Users/m/Downloads/data-tmp/hathitrust_post45fiction_metadata.tsv\"\n",
    "\n",
    "author_viaf = 'author_viaf'\n",
    "author_lccn = 'author_lccn'\n",
    "author_wikidata = 'wikidata_qid'\n",
    "\n",
    "author_authorized_heading = 'author_authorized_heading'\n",
    "oclc_owi = 'oclc_owi'\n",
    "isbns = 'isbns'\n",
    "\n",
    "ol_work = 'ol_work'\n",
    "\n",
    "wikidata_work_qid='wikidata_work_qid'\n",
    "wikidata_publisher_qid='wikidata_publisher_qid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_tsv, sep='\\t', header=0, low_memory=False)\n",
    "\n",
    "df_dropped = df.dropna(subset=[author_viaf,author_lccn,author_wikidata], how='all')\n",
    "\n",
    "print('Number of rows with one identifier populated:',len(df_dropped.index), 'out of ',len(df.index), len(df_dropped.index)/len(df.index)*100 )\n",
    "\n",
    "df_dropped = df.dropna(subset=[author_viaf], how='all')\n",
    "print('Number of rows with author_viaf populated:',len(df_dropped.index), 'out of ',len(df.index), len(df_dropped.index)/len(df.index)*100 )\n",
    "\n",
    "df_dropped = df.dropna(subset=[author_lccn], how='all')\n",
    "print('Number of rows with author_lccn populated:',len(df_dropped.index), 'out of ',len(df.index), len(df_dropped.index)/len(df.index)*100 )\n",
    "\n",
    "df_dropped = df.dropna(subset=[author_wikidata], how='all')\n",
    "print('Number of rows with author_wikidata populated:',len(df_dropped.index), 'out of ',len(df.index), len(df_dropped.index)/len(df.index)*100 )\n",
    "\n",
    "df_dropped = df.dropna(subset=[wikidata_work_qid], how='all')\n",
    "print('Number of rows with wikidata_work_qid populated:',len(df_dropped.index), 'out of ',len(df.index), len(df_dropped.index)/len(df.index)*100 )\n",
    "\n",
    "df_dropped = df.dropna(subset=[ol_work], how='all')\n",
    "print('Number of rows with open library ol_work populated:',len(df_dropped.index), 'out of ',len(df.index), len(df_dropped.index)/len(df.index)*100 )\n",
    "\n",
    "df_dropped = df.dropna(subset=[isbns], how='all')\n",
    "print('Number of rows with isbns populated:',len(df_dropped.index), 'out of ',len(df.index), len(df_dropped.index)/len(df.index)*100 )\n",
    "\n",
    "df_dropped = df.dropna(subset=[wikidata_publisher_qid], how='all')\n",
    "print('Number of rows with wikidata_publisher_qid populated:',len(df_dropped.index), 'out of ',len(df.index), len(df_dropped.index)/len(df.index)*100 )\n",
    "\n",
    "df_dropped = df.dropna(subset=[oclc_owi], how='all')\n",
    "print('Number of rows with oclc_owi populated:',len(df_dropped.index), 'out of ',len(df.index), len(df_dropped.index)/len(df.index)*100 )\n",
    "\n",
    "\n",
    "unique_owi = list(set(df_dropped[oclc_owi].tolist()))\n",
    "\n",
    "print(\"Nubmber of unique OWI ids\", len(unique_owi))\n",
    "\n",
    "isbns = list(set(df_dropped[isbns].tolist()))\n",
    "\n",
    "from collections import Counter\n",
    "isbns_count = {}\n",
    "\n",
    "for i in isbns:  \n",
    "    count = 1 \n",
    "    if type(i) == float:\n",
    "        pass\n",
    "    else:\n",
    "        count = len(i.split('|'))\n",
    "    if count not in isbns_count:\n",
    "        isbns_count[count] = 1\n",
    "    \n",
    "    isbns_count[count] = isbns_count[count] + 1\n",
    "\n",
    "print(isbns_count) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
